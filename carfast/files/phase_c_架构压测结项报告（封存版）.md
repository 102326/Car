# Phase C：本地架构实验室 · 压测结项报告

**High-Concurrency Architecture Stress Test – Final Archive Edition**

---

- **项目名称**：CarFast（Refactoring）
- **报告阶段**：Phase C（架构基建验证）
- **报告日期**：2026-01-23
- **测试人员**：指挥官 & Gemini
- **报告性质**：技术归档 / 架构验证（非生产 SLA 承诺）

---

## 1. 测试环境规格（Test Environment）

| 项目 | 规格 |
|---|---|
| CPU | AMD Ryzen 9 8945HX（16 Cores / 32 Threads） |
| 内存 | 32GB DDR5 |
| 操作系统 | Windows 11（WSL2 + Docker Backend） |
| 压力源 | JMeter（本机运行） |

### 架构拓扑

- **API 层**：FastAPI + Uvicorn（8 Workers，多进程）
- **搜索引擎**：Elasticsearch 集群（3 Nodes：es01 / es02 / es03）
- **数据库**：PostgreSQL（连接池隔离，仅低频接口使用）

> 注：本测试为**单机运行的分布式伪集群环境**，用于验证架构边界与算力极限，而非模拟真实生产部署。

---

## 2. 测试场景定义（Scenarios）

本阶段通过两类**性质完全不同**的压测场景，分别界定系统的**管道极限**与**真实业务算力基准**。

### 场景 A：管道极限测试（Pipeline Limit）

- **索引数据量**：极小（≈ 空索引）
- **分片结构**：单分片（1 Shard）
- **查询复杂度**：简单匹配，无聚合、无高亮
- **测试目的**：
  - 验证 FastAPI + ES 请求转发能力
  - 探测 OS / Docker / WSL2 网络协议栈上限

**结果摘要**：

- **QPS**：≈ 3500+ / sec
- **主要瓶颈**：Windows WSL2 网络桥接与本机资源竞争

> 该场景不代表真实业务负载，仅用于确认“网络与进程管道”能力上限。

---

### 场景 B：真实业务极限测试（Compute Limit）

- **索引数据量**：50,000 条（全字段）
- **分片结构**：3 Shards（全集群参与计算）
- **查询特征**：
  - Bool Query
  - Multi-match（多字段相关性计算）
  - Filters
  - 3 个聚合桶（Aggregations）
  - Highlight（高亮）
- **并发量**：1000 Threads（JMeter）

**测试目的**：

- 验证复杂搜索场景下的系统稳定性
- 测定 Elasticsearch 集群在单机条件下的真实算力边界

---

## 3. 核心测试结果（Golden Baseline）

| 指标 | 数值 | 评价 |
|---|---|---|
| 吞吐量（QPS） | **1261.5 / sec** | 真实业务负载下的稳定算力基准 |
| 异常率（Error %） | **0.00%** | 在 CPU 满载条件下无请求丢失 |
| 平均延迟（Latency） | ≈ 600 ms | 单机多进程 + 伪集群条件下的可接受水平 |
| CPU 使用率 | ≈ 1500% | 多核累积口径，约 15 个逻辑核心满载 |
| 内存占用 | ≈ 95%（30GB+） | 接近物理内存上限，但未触发 Swap |

> 注：CPU 使用率采用 Docker / 宿主机多核累积统计口径。

---

## 4. 架构分析与洞察（Architectural Insights）

### 4.1 吞吐量回落分析（3500 → 1261）

QPS 数值下降并非架构退化，而是测试目标从“空转管道”切换至“真实计算负载”的**物理必然结果**，主要原因包括：

1. **伪集群开销（Pseudo-Cluster Overhead）**
   - 单机运行 3 个 ES 节点
   - 分片查询需经历 Scatter / Gather / Reduce
   - 节点间序列化与通信成为纯内耗

2. **上下文切换成本（Context Switching）**
   - CPU 同时调度：
     - JMeter（压力源）
     - 8 个 FastAPI Worker
     - 3 个 ES 节点
   - 大量算力消耗在任务调度而非有效计算

3. **算力密度真实化**
   - 1261 QPS 代表：
     - 50k 数据规模
     - 3 分片并行
     - 含聚合与高亮的完整搜索请求
   - 属于该硬件条件下的稳定算力边界

---

### 4.2 关键架构验证结果（Validations）

#### ✅ 搜索隔离（Search Isolation）

- 所有高频搜索接口完全移除 PostgreSQL 同步依赖
- 压测期间数据库连接池保持静默
- 成功避免“搜索流量拖垮核心事务库”的系统性风险

#### ✅ 分片与集群机制

- Cerebro 监控显示数据均匀分布于 3 个节点
- 压测期间 3 个节点 CPU 同步升高
- 验证分片策略生效，全集群参与计算

---

## 5. 工程定性结论（Engineering Verdict）

- **综合评级**：Production Ready（生产级架构底座）
- **稳定性**：在 CPU / 内存接近物理极限时仍保持 0% 错误率
- **架构有效性**：系统瓶颈成功从数据库转移至计算节点，符合预期设计目标

> 在包含聚合与高亮的复杂搜索条件下，单机环境实现 1200+ QPS 且无异常，已达到中型互联网应用的工程性能标准。

---

## 6. 结论与开发规范（Conclusion & Standards）

基于 Phase C 的测试结果，确立以下后续开发约束与性能护栏：

### 性能基准线（Performance Guardrail）

- **本地开发环境安全水位**：≤ **1000 QPS**
- 超出该水位的性能评估，应在独立压测节点或拆分部署环境中进行

### 架构约束原则

1. **读写分离强约束**
   - 所有高频搜索接口禁止同步访问 SQL 数据库

2. **资源意识**
   - 聚合（Aggregation）与高亮（Highlight）为高 CPU 消耗能力
   - 业务中应按需启用，避免无约束使用

---

## 7. 结项声明（Closure）

Phase C（架构基建验证）目标已全部达成：

- 架构边界清晰
- 性能基准明确
- 风险位置可控

**本阶段正式结项，报告封存。**

