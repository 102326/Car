import sys
import os
import asyncio
import logging
import time

# ç¯å¢ƒè¡¥ä¸
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from sqlalchemy import select, func
from elasticsearch.helpers import async_bulk

from app.core.database import AsyncSessionLocal
from app.core.es import es_client
from app.models.car import CarModel
from app.services.es_service import CarESService
from app.services.car_assembler import fetch_and_assemble_car_docs

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger("CleanSync")

BATCH_SIZE = 100  # æ¯æ‰¹å¤„ç† 100 æ¡


async def main():
    logger.info("ğŸš€ [å…¨é‡åŒæ­¥] è„šæœ¬å¯åŠ¨...")

    # 1. ç¡®ä¿ç´¢å¼•å­˜åœ¨
    await CarESService.create_index_if_not_exists()

    start_time = time.time()
    total_synced = 0

    async with AsyncSessionLocal() as session:
        # 2. è·å–æ€»æ•° (ç”¨äºè¿›åº¦æ¡)
        count_stmt = select(func.count(CarModel.id))
        total_count = (await session.execute(count_stmt)).scalar()
        logger.info(f"ğŸ“¦ æ•°æ®åº“å…±æœ‰ {total_count} è¾†è½¦ï¼Œå‡†å¤‡åŒæ­¥...")

        # 3. æ¸¸æ ‡åˆ†é¡µæŸ¥è¯¢ (é¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰ ID æ’‘çˆ†å†…å­˜)
        # è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å…ˆæŸ¥å‡ºæ‰€æœ‰ IDï¼Œå¦‚æœ ID ä¹Ÿæ˜¯ç™¾ä¸‡çº§ï¼Œå»ºè®®ç”¨ keyset pagination
        stmt = select(CarModel.id)
        all_ids = (await session.execute(stmt)).scalars().all()

        # 4. æ‰¹é‡å¤„ç†å¾ªç¯
        client = es_client.get_client()

        for i in range(0, len(all_ids), BATCH_SIZE):
            batch_ids = all_ids[i: i + BATCH_SIZE]

            # A. æ‰¹é‡æŸ¥åº“ç»„è£… (Batch Fetch)
            docs = await fetch_and_assemble_car_docs(batch_ids)
            if not docs:
                continue

            # B. æ„é€  ES Bulk Actions
            actions = [
                {
                    "_index": CarESService.INDEX_NAME,
                    "_id": str(d["id"]),
                    "_source": d
                }
                for d in docs
            ]

            # C. æ‰¹é‡å†™å…¥ ES (Bulk Insert)
            try:
                success, failed = await async_bulk(client, actions, stats_only=True)
                total_synced += success
                print(f"\r   â³ è¿›åº¦: {total_synced}/{total_count} ({(total_synced / total_count) * 100:.1f}%)", end="")
            except Exception as e:
                logger.error(f"\nâŒ æ‰¹æ¬¡å†™å…¥å¤±è´¥: {e}")

    duration = time.time() - start_time
    print()
    logger.info(f"ğŸ‰ [å®Œæˆ] åŒæ­¥ {total_synced} æ¡æ•°æ®ï¼Œè€—æ—¶ {duration:.2f}ç§’")
    logger.info(f"âš¡ å¹³å‡é€Ÿåº¦: {total_synced / duration:.0f} docs/s")

    # å…³é—­èµ„æº
    await es_client.close()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass